{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleep stage classifier\n",
    "\n",
    "## Aim of project\n",
    "\n",
    "- Train a model to **classify** sleep data obtained from mice (*Mus musculus*) into wake, NREM sleep and REM sleep epochs. \n",
    "\n",
    "- Features  are derived from **continuous time series** muscle activty in the electromoyogram (EMG) and brain wave activity in the electroencephalogram (EEG). \n",
    "\n",
    "- An expert human sleep stage scorer classified each 5-second epoch into one of three classes (wake, NREM sleep or REM sleep) by visualizing the raw EEG and EMG.\n",
    "\n",
    "- Manual classification of sleep is a labor-intensive process. Developing a model to accurately and automatically classify stages of sleep from mouse EEG and EMG recordings has the potential to save sleep scientists a lot of time!\n",
    "\n",
    "\n",
    "## Features\n",
    "\n",
    "The data is imported from a **.mat** file. Each feature, the target class, and start time are saved as separate dictionaries in this file. The features dictionaries and class dictionary hold **continuous time series data** which **start at the same time** but are sampled at different **sampling frequencies**.\n",
    "\n",
    "- *Start*: The start time of all the features and the class\n",
    "\n",
    "- *EMG*: Muscle activity, sampled at 500 Hz\n",
    "\n",
    "- *Theta*: Brain wave activity in the theta band, sampled at 10 Hz\n",
    "\n",
    "- *Delta*: Brain wave activity in the delta band, sampled at 10 Hz\n",
    "\n",
    "- *T_D*: The theta: delta ratio, sampled at 10 Hz\n",
    "\n",
    "- *Alpha*: Brain wave activity in the alpha and beta bands, sampled at 10 Hz\n",
    "\n",
    "- *Low Gamma*: Brain wave activity in the low gamma band, sampled at 10 Hz\n",
    "\n",
    "- *Stage*: The sleep stage (**target class**) that each 5-second epoch was assigned to by the expert human scorer \n",
    "    - *wake* = 1\n",
    "    - *NREM sleep*  = 2\n",
    "    - *REM sleep* = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from MATLAB file and extract dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('example.mat')\n",
    "\n",
    "for key in data.keys():\n",
    "    if key.startswith('EMG'):           # extract feature dictionaries\n",
    "        emg_dict = data[key]\n",
    "    elif key.startswith('T_D'):\n",
    "        td_dict = data[key]\n",
    "    elif key.startswith('Delta'):\n",
    "        delta_dict = data[key]\n",
    "    elif key.startswith('Theta'):\n",
    "        theta_dict = data[key]\n",
    "    elif key.startswith('alpha'):\n",
    "        alphabeta_dict = data[key]\n",
    "    elif key.startswith('low_gamma'):\n",
    "        low_gamma_dict = data[key]\n",
    "    elif key.startswith('Stage'):            # extract class dictionary\n",
    "        stage_dict = data[key]\n",
    "    elif key.startswith('start'):             # extract start time\n",
    "        start_dict = data[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract feature data and align to the same timebase as the target class\n",
    "\n",
    "Because the continuous time series feature and class data start at the same time but are sampled at different sampling frequencies, the feature data need to be aligned to the target class data.\n",
    "\n",
    "The following code will extract the feature values from each feature dictionary and align it to the class data by summing the feature data every 5 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Determine how many epochs have been classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = np.size(stage_dict['codes'][0][0][:],0)-1     # we can't use the last epoch as there isn't a full 5 seconds at the end of the recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create a function to extract feature values and align to 5 second epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_features(feature_struct,num_epochs): \n",
    "    feature_data = feature_struct['values'][0][0][:,0]   # Extract feature data from each feature dictionary\n",
    "    Hz = int(1/feature_struct['interval'][0][0][0][0])  # Determine the sampling interval of the data points in this feature\n",
    "    datapoints_to_sum = Hz*5  # Calculate the number of data points in 5 seconds\n",
    "    data_slice = feature_data[0:(datapoints_to_sum*num_epochs)]  # prepare array data to be reshaped into feature matrix\n",
    "    feature_matrix = np.reshape(data_slice,(num_epochs,datapoints_to_sum))   # reshape data so can sum along rows\n",
    "    aligned_feature = np.sum(feature_matrix,1)    # sum along each row to get 5 second sums\n",
    "    return aligned_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Apply *align_features* function to feature dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emg = align_features(emg_dict, num_epochs)\n",
    "td = align_features(td_dict, num_epochs)\n",
    "theta = align_features(theta_dict, num_epochs)\n",
    "delta = align_features(delta_dict, num_epochs)\n",
    "alphabeta = align_features(alphabeta_dict, num_epochs)\n",
    "low_gamma = align_features(low_gamma_dict, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct dataframe for features and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'emg': emg, 'td' : td, 'theta': theta, 'delta': delta, \n",
    "    'alphabeta': alphabeta, 'low_gamma': low_gamma}\n",
    "df = pd.DataFrame(data=d)\n",
    "df['class'] = stage_dict['codes'][0][0][:-1,0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model to classify sleep stages: Support Vector Machine\n",
    "\n",
    "#### 1. Perform Train Test Split to split our data into training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['emg', 'td', 'theta', 'delta', 'alphabeta', 'low_gamma']]\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Perform feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Train the Model using a Support Vector Machine\n",
    "\n",
    "Because the number of samples (classfied epochs) is intermediate and the number of features small, I will first implement the SVM using a Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Make predictions on the test data (X_test) based on the fitted SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaluate predictions against actual test data (y_test) classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test,clf_predictions))\n",
    "print(classification_report(y_test,clf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is quite skewed (more of category 2 (NREM sleep) than category 1 (wake) or category 3 (REM sleep)), hence the F1-score gives the most useful metric in determining how good our model was. Our model does not fit the data perfectly and there may be some room for improvement. To this end, we will adjust our model using GridSearchCV to help us find the best hyperparameters.\n",
    "\n",
    "## Gridsearch\n",
    "\n",
    "#### Create hyperparameter dictionary for **C**, **gamma** and **kernel** for GridSearchCV and fit the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf_grid = GridSearchCV(SVC(),parameters,refit=True,verbose=3)\n",
    "clf_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report best estimator and make predictions for X_test off the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_grid_predictions = clf_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate predictions off the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,clf_grid_predictions))\n",
    "print(classification_report(y_test,clf_grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that we were not able to improve the F1-score of the model by optimizing the hyperparameters. In order to improve our model, we will then consider what other features might yield useful information that could improve the success rate of our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering additional features\n",
    "\n",
    "The time of day at which the features are recorded influences the likelihood of an epoch being classed as wake, NREM sleep or REM sleep (i.e. mice are nocturnal so during the day time they are more likely to be asleep). This being the case, we will extract a new feature, 'hour' which tells us what hour of the day it is.\n",
    "\n",
    "#### Find start time of recording and extract what hour of the day it is for each sample\n",
    "The start time of the recording can be obtained from the array, 'codes', in the dictionary, 'start_time'. The first 6 elements in 'codes' correspond to the 6-digit timestamp, HH:MM:SS. We first convert this 6 element array into a Python datetime. This is the start time of the recording ('t'). We next re-construct the actual time for each epoch in our DataFrame and extract the hour-of-the-day as a separate feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = start_dict['codes'][0][0][0:6:,0]    # Extract 6-element time information from start_dict\n",
    "start_hour = int(str(start_time[0]) + str(start_time[1]))  # Separate hour out\n",
    "start_minute = int(str(start_time[2]) + str(start_time[3]))   # Separate minute out\n",
    "start_second = int(str(start_time[4]) + str(start_time[5]))    # Separate second out\n",
    "t = dt.datetime(1900,1,1,hour = start_hour,minute = start_minute,second = start_second)   # Convert start time to Python datetime object\n",
    "\n",
    "elapsed_time = np.arange(0,(num_epochs),1)*5   # Construct time scale, indicating elapsed time in seconds (starting at 0, incrementing in 5-second intervals)\n",
    "df['timestamp'] = elapsed_time                 # Make column for elapsed_time\n",
    "df['timestamp'] = df['timestamp'].apply(lambda secs: t + dt.timedelta(0,secs)) # Convert elapsed_time into actual clock time by adding to start time 't'\n",
    "df['hour'] = df['timestamp'].apply(lambda x: x.hour)   # extract hour from timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below plot shows the distribution of each class, every hour during the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'hour', hue = 'class', data = df)\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title('Sleep classification by hour-of-the-day');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of previous and future epochs on current epoch\n",
    "\n",
    "When manually scoring the EEG and EMG and classifying each epoch to wake, NREM sleep or REM sleep, it is apparent that the classification of each epoch is not enitrely independent and is, to some degree, influenced by the epochs before and after it. For example, if both the epoch immediately prior to, and immediately after, a particular epoch are classed as 'wake', that epoch is also most likely a 'wake' epoch. This is demonstrated in the 'hypnogram' plot below where the class does not change over many epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,3))\n",
    "\n",
    "ax.plot(df['class'])\n",
    "ax.set_xlabel('epoch #')\n",
    "ax.set_ylabel('sleep stage class')\n",
    "ax.set_title('hypnogram');\n",
    "ax.set_yticks([1, 2, 3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This property makes logical sense: after all, wake and sleep occur in consolidated bouts of several minutes long in the mouse.\n",
    "\n",
    "Although the class of the surrounding epochs will be hidden from the model, we can provide the model with information about the prior and following epochs by engineering the existing features.\n",
    "\n",
    "To this end, for each EEG/EMG feature, I will create two new features containing:\n",
    "\n",
    "1) the moving average for the 10 seconds (2 epochs) preceding the start of the epoch\n",
    "\n",
    "2) the moving average for the 10 seconds (2 epochs) following the start of the epoch\n",
    "\n",
    "#### 1. Define a function to calculate the moving average over each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_post_movavg(input_column):\n",
    "    rolling_avg = input_column.rolling(2).mean()\n",
    "    pre_movavg = np.append(rolling_avg[1:],np.nan)\n",
    "    post_movavg = np.append(rolling_avg[4:],(np.zeros(4)+np.nan))\n",
    "    return pre_movavg, post_movavg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Apply 'pre_post_mov avg' to each EEG/EMG feature and add to feature dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pre_emg'],df['post_emg'] = pre_post_movavg(df['emg'])\n",
    "df['pre_td'],df['post_td'] = pre_post_movavg(df['td'])\n",
    "df['pre_theta'],df['post_theta'] = pre_post_movavg(df['theta'])\n",
    "df['pre_delta'],df['post_delta'] = pre_post_movavg(df['delta'])\n",
    "df['pre_alphabeta'],df['post_alphabeta'] = pre_post_movavg(df['alphabeta'])\n",
    "df['pre_low_gamma'],df['post_low_gamma'] = pre_post_movavg(df['low_gamma'])\n",
    "df.dropna(inplace = True)      # remove NaN values introduced into the dataframe from the pre and post moving average "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Retrain the SVC model with additional features\n",
    "\n",
    "#### 1. Perform Train Test Split on the updated feature dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['emg', 'td', 'theta', 'delta', 'alphabeta', 'low_gamma', \n",
    "       'hour', 'pre_emg', 'post_emg', 'pre_td', 'post_td', 'pre_theta', 'post_theta', 'pre_delta',\n",
    "       'post_delta', 'pre_alphabeta', 'post_alphabeta', 'pre_low_gamma',\n",
    "       'post_low_gamma']]\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Exploit sklearn Pipeline to perform feature scaling, fitting to an SVC, and using GridSearch to determine hyperparameters in one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(StandardScaler(),SVC())\n",
    "param_grid = {'svc__kernel':('linear', 'rbf'), 'svc__C': [0.1,1, 10, 100, 1000], 'svc__gamma': [1,0.1,0.01,0.001,0.0001]}\n",
    "gs = GridSearchCV(pipe, param_grid,verbose=3)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Report best estimator and make predictions for X_test off the model that includes newly engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_predict = gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Evaluate predictions off the test data (X_test ) from the current model that includes newly engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,pipe_predict))\n",
    "print(classification_report(y_test,pipe_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "The F1 scores improved by a couple of percentage points for both wake and REM sleep. Additionally, we can see from the confusion matrix that wake (class 1) was never misclassified as REM sleep (class 3). On the other hand, NREM sleep and wake were sometimes misclassified as each other and REM sleep was also misclassified as either wake or NREM sleep.\n",
    "\n",
    "Ways to improve the success of the classifier:\n",
    "\n",
    "- Train the classifier on **more data**, specifically including data from around the whole 24 hour clock (only data from between 10am and 4pm were included here)\n",
    "\n",
    "- More intensive **engineering of existing features**. For example, 'hour of day' could be replaced by time periods of lower time resolutions (e.g. morning, afternoon, evening, night etc). Alternatively, it could make sense to combine EEG and EMG data into novel features. i.e. engineer a new feature that calculates the TD:EMG ratio. High values of TD are associated with both REM sleep *and* wake but high EMG values are only assoicated with wake (because there is very little muscle acitivity obsrved when mice are sleeping!) Including this as a feature may enable better distinction between wake and REM sleep.\n",
    "\n",
    "*We will explore how including a newly engineered feature, TD:EMG ratio, will assist in training the classifier:*\n",
    "\n",
    "#### 1. Calculate TD:EMG ratio (and pre and post TD:EMG ratios) and include in feature dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['td_emg'] = df['td']/df['emg']\n",
    "df['pre_td_emg'] = df['pre_td']/df['pre_emg']\n",
    "df['post_td_emg'] = df['post_td']/df['post_emg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['emg', 'td', 'theta', 'delta', 'alphabeta', 'low_gamma', 'class',\n",
    "       'hour', 'pre_emg', 'post_emg', 'pre_td', 'post_td',\n",
    "       'pre_theta', 'post_theta', 'pre_delta', 'post_delta', 'pre_alphabeta',\n",
    "       'post_alphabeta', 'pre_low_gamma', 'post_low_gamma', 'td_emg',\n",
    "       'pre_td_emg', 'post_td_emg']]\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Perform Train Test Split and utilize the previously instantiated 'pipe' Pipeline to scale data and fit SVC with appropriate hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "new_gs = GridSearchCV(pipe, param_grid,verbose=3)\n",
    "new_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Report best estimator and make predictions for X_test off the model that includesTD:EMG ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipe_predict = new_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Evaluate predictions off the test data (X_test ) from the current model that includes TD:EMG ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,new_pipe_predict))\n",
    "print(classification_report(y_test,new_pipe_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "After including the TD:EMG feature, the model appears to be classifying the sleep data perfectly. Had this not been the cases, we could have tried to improve the classifier in several ways:\n",
    "\n",
    "- including additional features such as heart rate and breathing rate\n",
    "- engineer additional features from the EEG and EMG features similarly to the TD:EMG features\n",
    "- Explore other modes (e.g. logistic regression, decision trees, random forest classifers, artificial neural networks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
